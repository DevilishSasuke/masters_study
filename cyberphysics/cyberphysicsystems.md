# Повышение точности точности малых моделей детекции объектов

## Постановка задачи

В задачах компьютерного зрения, где требуется распознавание **объектов в режиме реального времени на мобильных и малопроизводительных устройствах**, модель должна обеспечивать **высокую точность** и **скорость работы** при **минимальных вычислительных затратах**.

Стандартные характеристики таких устройств схожи с следующими:

* Процессор: 4-ядерный, тактовая частота 2.2 ГГц

* Графический процессор: обработка изображения размером до 1920 * 1080

* ОЗУ: до 4 ГБ

При таких ограничениях невозможно использовать крупные нейронные сети, поэтому требуется упрощение архитектуры нейросети, например уменьшение **числа слоев**, **фильтров** и **параметров**

Основная проблема заключается в том, что упрощение архитектуры нейронной сети приводит к значительному снижению точности распознавания. 

Основной целью является добиться точности, близкой с исходной моделью при меньшем числе параметров и более высокой скорости работ.

## Параметры задачи

| Категория            | Основные параметры                                                                                            | Влияет на                                           |
| -------------------- | ------------------------------------------------------------------------------------------------------------- | --------------------------------------------------- |
| **Архитектура сети** | количество слоёв $n$, <br/>шаг карты признаков (stride feature map) $feat_{st}$, <br/>количество фильтров $f$ | скорость работы (FPS) и точность (mAP)              |
| **Входные данные**   | размер входного изображения $(W, H)$                                                                          | точность распознавания                              |
| **Якори (anchors)**  | количество якорных рамок $k$ и их размеры $(w_a, h_a)$                                                        | качество локализации объектов и IoU                 |
| **Метрики оценки**   | mAP, Precision, Recall, IoU, FPS, $T_1$(время обработки одного кадра)                                         | позволяет оценить скорость и точность работы модели |

### Обозначение метрик и параметров

* **Pooling** - операция уменьшения размера карты признаков, сохраняя наиболее важную информацию

* **Precision** - показывает, какая доля найденных моделью объектов действительно является корректной (в процентах или от 0 до 1)

* **Recall** - показывает, какая доля реальных объектов была найдена моделью (в процентах или от 0 до 1)

* **IoU (Intersection over Union)** - показывает, насколько точно предсказанные области покрывают исходные (от 0 до 1)

* **mAP (mean Average Precision)** - среднее значение точности по всем классам и порогам IoU. Основная метрика для сравнения моделей (в процентах)

* **FPS (frames per second)** - количество обрабатываемых кадров в секунду, показывает производительность ($\frac{кадры}{сек}$)

### Формулировка задачи оптимизации

Данную задачу можно представить в виде задачи оптимизации.

Пусть существуют параметры:

* $W$ - ширина входного изображения (пиксели) [1]

* $H$ - высота входного изображения (пиксели) [2]

* $n$ - количество слоёв нейронной сети [3]

* $k$ - количество якорных рамок [4]

Необходимо набрать такой набор параметров $(W, H, n, k)$ при котором:

* точность $mAP \rightarrow max$ [7]

* частота кадров $FPS \rightarrow max$ (т.к. $FPS = \frac{1}{T_1}$, а $T_1 \rightarrow min$) [8]

при выполнении следующих ограничений:

* $n < n_{max}$ [3]

* $mAP_{raw} = mAP_{n_0}-\Delta_{raw}$, [6] - это нижняя граница mAP при неоптимизированном наборе параметров (W, H, k), где $\Delta_{raw}$ - допустимое снижение точности

* $mAP(n)\ge mAP_{raw}+\Delta$, [7] где $\Delta$ - желаемый прирост точности в процентах (задается исходя из характеристик задачи)

* $FPS(W,H,n,k)$ [8] $\ge FPS_{min}$ [5] ($FPS_{min}$ задается исходя из задачи)

## Алгоритм повышения точности сети

### Анализ архитектуры

1. Зафиксировать начальное количество слоев как $n_0$

2. Уменьшить количество слоев до $n$ [3] $< n_0$ следующим образом:
   
   * Установить диапазон поиска $n \in [n_{min}; n_{max}]$ 
     (изначально $n_{min} = 5, n_{max}=n_0 - 1$)
   
   * Вычислить $n_{mid} = \frac{n_{min}+n_{max}}{2}$
   
   * Измерить метрики: $mAP(n_{mid}), FPS(n_{mid})$ [7][8]
   
   * При
     
     * $FPS(n_{mid}) \ge FPS_{min}$ [5]
     
     * $mAP(n_{mid})\ge mAP_{raw}$ [6]
     
     уменьшаем глубину модели $n_{max} = n_{mid}$ 
   
   * Иначе $n = n_{max}$ [3] (находим последнее удовлетворяющее значение)

### Изменение входных данных

1. Изменить размер входного изображения $W_n × H_n$ [1][2] по числам, кратным 32 (примеры: уменьшение $640 \rightarrow 416 \rightarrow 320$, увеличение $416 \rightarrow 512 \rightarrow 640$)

2. Оценить изменения mAP и FPS [7][8]

3. Отметить зависимость: 
   $mAP∝f_1(W_n,H_n​)$,
   
   $FPS∝f_2(Wn​,Hn​)$ - (время обработки обратно пропорционально частоте кадорв)
   
   $f_1, f_2 - $ функции, описывающая зависимость точности  и количества кадров от разрешения входного изображения соответственно

### Оптимизировать якорные рамки

1. Масштабировать рамки по формуле: 
   $(w_r, h_r) =(\frac{W_n}{W_i}×w_t, \frac{H_n}{H_i}×h_t)$
   
   * $(w_t, h_t)$ - граничные рамки исходного значения (пиксели)
   
   * $(w_r, h_r)$ - ремасштабированные рамки (пиксели)
   
   * $(W_n,H_n)$ - исходное разрешение входа сети (пиксели)
   
   * $(W_i, H_i)$ - ширина и высота входного избражение (пиксели)
   
   Формула обеспечивает пропорциональное масштабирование якорных рамок под новый размер.

2. Провести кластеризацию k-средних по ширине и высоте рамок:
   $(w_c, h_c) = k$-$means(w_r, h_r)$
   
   * $(w_c, h_c)$ - $k$ центров кластеров, соответствующие усредненным размерам объектов 

3. Найти оптимальное количество кластеров $k$ [4] с помощью силуэта средних коэффициентов:
   
   * Проэкспериментировать со значением $k$ от 3 до 15
   
   * При каждой итерации вычислять средний силуэт по всем точкам:
   
   * $\bar{S}(k) = \frac{1}{n}\sum_{i=1}^{n} S(i)$
     n - общее количество элементов, участвующих в кластеризации
     
     * $S_k = \frac{b - a}{max(a, b)}$,
       a - среднее внутрикластерное расстояние,
       $b$ - ближайшее межкластерное расстояние
   
   * Максимум среднего $\bar{S}(k)$ определит оптимальное значение $k$

### Нормализация якорей

Нормализуем размеры якорных рамок

$(w_a, h_a) = (\frac{w_c}{feat_{st}}, \frac{h_c}{feat_{st}})$

* $w_a, h_a$- размеры рамок в масштабе feature map, то есть в тех единицах, с которыми работает последний слой модели

* $feat_{st} = 2^n$ - шаг карты признаков, где сеть содержит $n$ слоев max pooling

Это необходимо, чтобы размер якорей соответствовал масштабу признаков на последнем уровне сети.

### Оценка результатов

1. Измерить метрики $Precision, Recall, mAP, FPS, IoU$

2. Проанализировать зависимости параметров
   
   * увеличение $W_n, H_n$  [1][2] $\rightarrow$​ рост $mAP$, падение $FPS$ 
   
   * уменьшение $n$ [3] $\rightarrow$ рост $FPS$, падение точность $mAP$
   
   * увеличение $k$ [4] $\rightarrow$ рост $IoU$

3. Сделать выводы, удовлетворяют ли текущая конфигурация и метрики целевым ограничениям

## Заключение

Представленный подход позволяет подбирать архитектурные и входные параметры модели под доступные вычислительные ресурсы.

Это обеспечивает достижение показателей точности, сопоставимых и сходной моделью [источник 1], при значительно меньшей сложности модели, что важно для систем компьютерного зрения, работающих на мобильных и малопроизводительных устройствах.



| Модель                      | Recall (%) | Precision (%) | Avg. IoU (%) | Speed (FPS) | mAP (%) |
| --------------------------- | ---------- | ------------- | ------------ | ----------- | ------- |
| **Базовая модель**          | 80         | 78            | 75           | 5–20        | 72      |
| **Оптимизированная модель** | 85         | 84            | 82           | 50–100      | 82.21   |

## Источники

1. [Tarek Teama, Hongbin Ma, Ali Maher, and Mohamed A. Kassab. 2019. Real Time Object Detection Based on Deep Neural Network. In Intelligent Robotics and Applications: 12th International Conference, ICIRA 2019, Shenyang, China, August 8–11, 2019, Proceedings, Part IV. Springer-Verlag, Berlin, Heidelberg, 493–504.](https://link.springer.com/journal/41315)
